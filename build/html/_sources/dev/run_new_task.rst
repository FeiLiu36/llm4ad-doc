Run your problem and LLM
============================

.. note::
    This tutorial will demonstrate a basic LLM4AD pipeline to solve an automated algorithm design task.

1. Prepare a `Sampler`
-----------------------

.. note::
    The `Sampler` class (an abstract class) defines how to access the LLM.
    You can either deploy an LLM locally on your own device/server or use an LLM API.
    The user should create a new child class of the `Sampler` class (extend `Sampler`) and implement (override) the `draw_sample` function.

Initialization of the user-defined sampler class
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

There is a keyword argument `auto_trim` in the `Sampler` class, with a default value of `True`. This means that regardless of whether the user chooses a code completion model (such as StarCoder, CodeLlama-Python, etc.) or a chat model (GPT series, Llama series, etc.), we can automatically identify the “useful part” without descriptions and truncated code.

.. tip::
    Therefore, unless there is a special issue, please **always leave 'auto_trim' default**.

Implementation of the draw_sample function
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The `draw_sample` function decides how to obtain the generated content from the LLM and return the `str`-typed content

.. note::
    feel free to return the answer generated by LLM, which may incorporate some useless descriptions, as they will be trimmed automatically by our trimmer).

Here, we show a brief example of using LLM API.

.. code:: python

    from llm4ad.tools.llm.llm_api_https import HttpsApi

    # note that the 'host' has no 'https'
    sampler = HttpsApi(host='api.bltcy.ai', key='Your API key', model='gpt-3.5-turbo', timeout=30)

You can also implement your own sampler.

.. code:: python

    import llm4ad
    import time
    import http.client
    import json

    class MySampler(llm4ad.base.Sampler):
        def __init__(self):
            super().__init__()

        def draw_sample(self, prompt: str | Any, *args, **kwargs) -> str:
            while True:
                try:
                    conn = http.client.HTTPSConnection(f'{api_endpoint}', timeout=30)
                    payload = json.dumps({
                        'max_tokens': 512,
                        'model': 'gpt-3.5-turbo',
                        'messages': [{'role': 'user', 'content': prompt}]
                    })
                    headers = {
                        'Authorization': f'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx',
                        'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',
                        'Content-Type': 'application/json'
                    }
                    conn.request('POST', '/v1/chat/completions', payload, headers)
                    res = conn.getresponse()
                    data = res.read().decode('utf-8')
                    data = json.loads(data)
                    response = data['choices'][0]['message']['content']
                    return response
                except Exception as e:
                    continue

2. Prepare a template program
-------------------------------

.. note::
    The template program is the initial point of algorithm optimization. Please carefully design a template program and spend enough time on it!

The following information is suggested to be considered and addressed in your template program:

- Import all packages that will be used or those that are potentially used in future optimization processes.

- You can also define global variables and classes that may be useful in your template program (if necessary).

- An intuitive function name.

- The type of each argument (labeled by type-hint).

- The return value of the function.

- A brief yet detailed docstring about each argument and the return value.

.. important::
    Please note that the template program should be executable for all methods and should be valid/feasible/legal for methods except EoH.

Assuming that we are going to solve the Online Bin Packing problem, an example template program is shown below:

.. code:: python

    template = '''
    import numpy as np

    def priority(item: float, bins: np.ndarray) -> np.ndarray:
        """Returns priority with which we want to add item to each bin.
        Args:
            item: Size of item to be added to the bin.
            bins: Array of capacities for each bin.
        Return:
            Array of same size as bins with priority score of each bin.
        """
        return bins - item
    '''

3. Prepare an `Evaluator`
-------------------------

.. note::
    The `Evaluator` class determines how to assess the score of a given algorithm under specific settings and tasks, which is typically task-dependent. Therefore, we may design a new `Evaluator` for a specified problem. The Evaluator class (an abstract class) is a user interface. We should define a child class of `Evaluator` (which extends the `Evaluator` class).

Initialization of the Evaluator class
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

By passing the respective argument to the Evaluator, the user can specify whether to use numba acceleration, protected division, or timeout seconds for code execution. Details about all arguments can be found in the base_package/evaluate section of this doc.

Implementation of the evaluate_program function
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The user should override the `evaluate_program` function in the Evaluator class (where the `evaluate_program` function remains unimplemented). The evaluate_program function evaluates the algorithm and gives a score. If you think the algorithm is infeasible/invalid/illegal, the user should return `None`. Otherwise, an int/float value or a "comparable" value (which may implement `>` operator between them) is desired.

.. important::
    If you think the algorithm to be evaluated is infeasible/invalid/illegal, the user should return `None`. Otherwise, an int/float value or a "comparable" value (which may implement `>` operator between them) is desired.

.. tip::
    Here you don't have to concern the evaluation time, as we will terminate the evaluation automatically in the backend if you have set `timeout_second` parameter.

The first argument of the function is a `program_str`, which is a `str` type of the algorithm to be evaluated. If you set the `use_numba_accelerate` or similar settings to `True` in the initialization, you will obtain a `str` typed function that has been modified. This `str` is provided to let you:

- Compile and execute the code with your own requirements.

- Consider the length or other features of the code.

- Other usages such as calculating the "novelty" of the code or checking if the code has been evaluated before.

The second argument of the function is a `callable_func`, which is an executable object. You can simply call (invoke) it by passing arguments to `callable_func`, such as `callable_function(arg0, arg1)`.

Feel free to use the platform-provided evaluator for the Online Bin Packing problem.

.. code:: python

    import llm4ad
    evaluator = llm4ad.problem.online_bin_packing.OBPEvaluator()

4. Specify a profiler and a logger (if necessary)
-------------------------------------------------

The profiler and logger will log your experiment locally/online for the convenience of monitoring, comparing, and summarizing your experiments.

.. note::
    Please note the type of the profiler may depend on the method you use. Assuming that we are using EoH.

.. code:: python

    from llm4ad.method.eoh.profiler import EoHWandbProfiler

    profiler = EoHWandbProfiler(wandb_project_name='obp',
                                log_dir='./logs/eoh_obp',
                                name='eoh_run1',
                                group='eoh')

5. Set parallel parameters and run.
------------------------------------

Pass above argument to EoH and run.

.. note::
    The `num_samplers` refers to the number of threads in that may access to the LLM simultaneously. The `num_evaluators` refers to the size of process execute pool, indicating the maximum processes used during evaluation (we may evaluate multiple algorithms in the same time).

.. caution::
    We use multi-threading for sampler, and multi-processing for evaluator. This means that we are using multi-core CPU during evaluation. Please kindly set these parameters to ensure safety.

.. code:: python

    from llm4ad.method.eoh import EoH

    eoh = EoH(
        template_program=template,
        sampler=sampler,
        profiler=profiler,
        evaluator=evaluator,
        max_sample_nums=1000,
        num_samplers=4,
        num_evaluators=4
    )
    eoh.run()
